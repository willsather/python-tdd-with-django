# Section 5: Machine Learning and Decision Trees

## Machine Learning Introduction

What even is Machine Learning? Although some might equate artificial intelligence and machine learning to robots and
aliens, it actually isn't nearly that dystopian.

The official [Webster Dictionary](https://www.merriam-webster.com/words-at-play/what-does-machine-learning-mean)
describes machine learning:

    The term machine learning (abbreviated ML) refers to the capability of a machine to improve its own performance. 

    It does so by using a statistical model to make decisions and incorporating the result of each new trial into that model. 
    In essence, the machine is programmed to learn through trial and error.

In very simplified terms, machine learning is a subset of artificial intelligence. Primarily, machine learning is a
computer (a machine) using training data, statistics, and data science (often a lot of complex mathematics) to create a
machine learning model.

Furthermore, a model can then be used for making predictions, based on the existing data. Throughout these examples,
there will be two types of data being referred to:

1. Training Data: existing data used to train the model (data the model will know about)
2. Testing Data: existing data used to test the accuracy of the model (data the model will not know about)


Testing the model on data it hasn't seen before is a sound way to actually validate the model is predicting with a
certain degree of confidence.

In a general sense, to create an effective model you can often follow the standard set of steps:

1. Prepare your dataset
2. Split your dataset into `training data` and `testing data`
3. Fit your model using a classifier with the `training data`
4. Test your model's accuracy with `testing data`
5. Deploy your model

Seems to make sense so far, but what about this `classifier`. What even is that?

In the area of machine learning, you will use a `classifier` (Classification Algorithm) to fit your training data. This
process will result in an output of a machine learning `model`. As you might have expected, there is a large variety of
different classification algorithms that you can use with a variety of datasets and desired prediction models.

Although this example won't go into much detail of many available classification algorithms, the base differentiator is
whether you are looking for a `Supervised` or `Unsupervised` machine learning algorithm. What is the difference?
Supervised (described by the process of human intervention or supervision) algorithms are used with `labeled data` where
the dataset has been processed, cleaned, formatted, and labeled. This example is using `labeled data` because the
dataset specifies what each column (Commonly known as a `Feature`) represents (ie: a property of a `Penguin`,
like `body_mass_g`)

## Decision Trees

This example Django REST Framework application will be using a Decision Tree classifier to build a machine learning
model. Given the `Palmer Penguins` dataset and the current goal of predicting the type of `Penguin` species, a decision
tree will suite the problem well.

What is a decision tree? Well, it's exactly how it sounds. It's a tree like structure where each node is a decision
point and each leaf node is the respective output (This would be the prediction). For example, if you are testing
a type of `Penguin`, an extremely simplify decision tree might look like this:

![](assets/basic-penguin-decision-tree.jpg?raw=true "Basic Penguin Decision Tree")

However, given the `Penguin` object and its various attributes, a decision tree predicting the species of a `Penguin`
would not be this simple. In reality, it looks like this:

![](assets/calculated-penguin-decision-tree.png?raw=true "Calculated Penguin Decision Tree")

## Testing Model Creation

Now, you know a little about decision trees, but how do you actually create one **AND** more importantly, how can
you approach solving this problem using Test Driven Development?

Because this guide primarily focuses on testing and consuming a machine learning model through a REST endpoint, this
won't walk through all the nuances and specifics of creating a model. The code and dependencies used are listed below,
but for brevity this guide won't focus on creating, testing, and validating the decision tree. However, the
aforementioned information is still quite useful in understanding `how` the model works in order to effectively test and
use it.

Below in the `Continue Learning` section, there will be plenty of resources to continue your learning on models and TDD /
testing practices in creation of a model. An important thing to note is that TDD often is discussed in the realm of
software development, but it can also be used (in a fashion) to validate machine learning models. At the core, it's
a `means to an end` that allows you to deliver fast and lower defects. This goal isn't just unique to software, but also
data science!

One more thing to note is that even though this example uses a single project where the REST endpoint and the machine
learning model all in the area, this
often isn't the case. It even is common to have different teams building the model and building the software. However,
for these
examples keeping all the logic in one repository is easier to share, discuss, and explain.

At the end of the day, there isn't `one-size-fits-all` strategy for TDD and machine learning. Some questions you might
find valuable to ask yourself and your team:

1. What is the structure of my team
2. Where is the model being built and where it will be located

These things will contribute to what tests you will write, to what degree, and where the tests will live in order to
maximize confidence in the product and the model.

## Creating Decision Tree Model

The general file structure looks like:

```text
.
├── Predict_PenguinSpecies_DecisionTree_Model.sav
├── __init__.py
├── model
│        ├── __init__.py
│        ├── accuracy.py
│        ├── assets
│        │       ├── basic-penguin-decision-tree.png
│        │       └── calculated-penguin-decision-tree.png
│        ├── model.py
│        ├── predict.py
│        └── save_figure.py
├── penguins.csv
└── tests
    ├── __init__.py
    └── test_prediction.py
```

where you will have a few primary files:

1. `model.py`: the main file where the data is prepared, classifier is fit, and model is exported
2. `predict.py`: the file to help in testing model, actually calls `predict` function
3. `save_figure.py`: the file that outputs a visual `png` representation of the model
4. `accuracy`: the file that calculates the accuracy of the trained model against `testing_data (split into x_test and y_test`


`model.py`
```python
import pandas as pd
import joblib

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

from accuracy import accuracy
from save_figure import save_figure

# This example read from a local CSV file for simplicity,
# but your data source can come from anywhere.  As you scale,
# there exist tools to help manage large datasets
df = pd.read_csv("../penguins.csv")
df = df.dropna()

# X = Feature Data
X = df.drop(['species', 'year'], axis=1)

# Y = Target Data
y = df['species']

"""
Decision Trees (at least in Scikit Learn), do not support 
categorical data in a decision tree, so for our Penguin example,
the "sex" field must be One Hot Encoded to properly be trained.

One hot encoding replaces categorical data with binary, numerical data
like shown below:

| bill_length_mm | sex |
------------------------
|     125        | male|

turns into

| bill_length_mm | is_Male |
----------------------------
|     125        |    1    |

pandas has a built in One Hot Encoder called "get_dummies"
"""
X_encoded = pd.get_dummies(X, drop_first=True)

# Split up training and testing data
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)

# Create Decision Tree classifier object
model = DecisionTreeClassifier()

# Train Decision Tree Classifier
model = model.fit(X_train, y_train)

# Test accuracy when training model
accuracy(model, X_test, y_test)

# Save PNG visualization of decision tree
save_figure(model=model, feature_names=X_encoded.columns)

# Save model
joblib.dump(model, '../Predict_PenguinSpecies_DecisionTree_Model.sav')
```

2. `predict.py`
```python
import pandas as pd
import joblib


def predict(data):
    # Initialize data to lists.
    new_data = [data]

    # Creates DataFrame for new data.
    new_df = pd.DataFrame(new_data)

    # Load model
    loaded_model = joblib.load('../Predict_PenguinSpecies_DecisionTree_Model.sav')

    # Create new prediction with dataframe
    return loaded_model.predict(new_df)
```

3. `save_figure.py`
```python
import matplotlib.pyplot as plt
from sklearn import tree


def save_figure(model, feature_names):
    fig = plt.figure(figsize=(25, 20))
    plt.suptitle(t="Palmer Penguins Species Decision Tree", fontsize="xx-large")
    tree.plot_tree(model,
                   filled=True,
                   feature_names=feature_names)
    fig.savefig("./assets/calculated-penguin-decision-tree.png")
```

4. `accuracy`
```python
from sklearn import metrics


def accuracy(model, x_test, y_test):
    # Predict the response for test dataset
    y_pred = model.predict(x_test)

    # Model Accuracy, how often is the classifier correct?
    print('Accuracy: {0:.4f}%'.format(100 * (metrics.accuracy_score(y_test, y_pred))))
```

## Wrap Up

After all of this, you have now learned a little about machine learning and decision trees, as well as actually creating
a decision tree model. Although this might seem unrelated to the REST endpoint, these steps allow you to continue
building more complex, useful API endpoints. As machine learning has rapidly grown in usefulness, importance, and
popularity, understanding and integrating topics like this into your projects can be quite useful.  

## Continue Learning

[SciKit Learn](https://scikit-learn.org/stable/)

[Pandas](https://pandas.pydata.org/)
